# Question 1
> Describe how, in your opinion, recent developments in computer architecture and computer design  
> have influenced operating system design. Include aspects on processes management,  
> memory management, file system design, and disks.  
> [10 marks - comprehension]

1. Process management
  - Greater processing power and more memory = ability to multiprocess
  - OS needs to provide APIs for creating and managing user processes
  - OS also needs to schedule processes so maximise CPU usage and share resources evenly

2. Memory management
  - Much more memory available now, and shared between multiple processes
  - Need to secure memory access so memory addresses can only be accessed by owning process(es) 
  - Processes now consume much more memory - need to perform swapping to keep only what is needed
in memory = implement paging

3. File system design (!)
  - Hard disks have much greater capacities now
  - Need to be able to track available space in the disk
  - Most file systems keep a list of blocks of fixed size, in a bitmap or linked list

4. Disks
  - Hard disks are significantly slower than volatile memory or CPU because of moving head
  - OS has to try to maximise the usage of the disk using scheduling
  - Order queued operations to try to maximise use in one movement of the read/write head

# Question 2
> Keeping in mind the implementation differences between threads and processes on an operating  
> system level, explain why thread creation and switching are faster than process creation and  
> switching.  
> [3 marks - comprehension]

- Threads share more things between each other - data, code and files
- This means context switching from one thread to another (of same process) has less overhead
- The address space remains the same between them

>In which situations would you favour user level threads ? In which situations would you favour kernel level threads. Explain your answer. [2 marks - comprehension]

1. User-level threads
  - Where maximum performance is required - avoids system calls which trigger context switching
  - Where portability is required - not all operating systems provide kernel thread implementation

2. Kernel-level threads
  - In most other cases - API is simpler to use for programmers

> Round Robin is said to favour CPU bound processes over I/O bound processes.  
> Explain why may this be the case (if this is the case at all)  
> [2 marks - comprehension] 

- RR loops around the queue, executing each process in turn (maybe with time slice)
- I/O bound processes will use little of their allocated time, yet have to wait for all CPU bound 
processes to take their turn

> Illustrate the use of round robin, shortest job first, and highest priority first scheduling  
> algorithms for the processes given below (all processes arrive at the same time). 

1. Scheduling timeline (time slice = 50)
  - SJF:
    - C: 0 - 11
    - D: 12 - 26
    - A: 27 - 57
    - B: 58 - 114

  - Priority:
    - A: 0 - 31
    - B: 32 - 89
    - C: 90 - 100
    - D: 101 - 116

  - RR:
    - A
    - B
    - C
    - D
    - A
    - B
    - A
    - B

2. Average response time

# Question 3
> Explain why hard links do not work across different machines
> [2 marks - comprehension]

Hard links refer to the i-node of the file that they point to.  
Since these differ between filesystems, if a hard link is copied to another filesystem, it is
highly unlikely that the copy will refer to the desired file

> Cylinder skew adds an offset to the sectors on adjacent cylinders on traditional magnetic hard
> drives. If a disk rotates at 10000 rpm, the seek time between two adjacent cylinders is 1
> millisecond, and each track contains 600 sectors, how many sectors should the cylinder skew be?
> [2 marks - comprehension] 

10,000 rpm = 1000/6 rps
1 ms = 0.001 s
so 1 ms causes 1/6 of a revolution
1/6 *600 = 10 sectors passed in 1 ms
So cylinder skew should be 10 sectors

> Consider a disk with 300 tracks, and the following sequence of requested tracks 
> 61, 149, 230, 48, 216, 54, 192, 262, 220, 255. 
> Calculate the number of tracks crossed when the following algorithms are used.
> Assume that the disk starts at position 66 and is moving in the up position (i.e. 1 to 300).
> [6 marks - application]

1. FCFS
  - 61 = +5
  - 149 = +88
  - 230 = +81
  - 48 = +182
  - 216 = +168
  - 54 = +162
  - 192 = +138
  - 262 = +70
  - 220 = +42
  - 255 = +35
  - Total: 971

2. Shortest seek time
  - 61 = +5
  - 54 = +7
  - 48 = +6
  - 149 = +101
  - 192 = +43
  - 216 = +24
  - 220 = +4
  - 230 = +10
  - 255 = +25
  - 262 = +7
  - Total: 231

3. Circular scan w/ look

# Question 4
> Briefly describe 3 contiguous memory schemes based on partitioning.
> [6 marks - knowledge] 

> What is thrashing? Explain why it can happen.
> [2 marks - comprehension]

Thrashing in when an OS repeatedly swaps memory pages in and out of main memory and the swap
storage as they are requested.  
This can occur in scenarios of high memory usage where all pages are in use.

> Describe the principle behind address relocation. Why is it necessary and why is it useful?” [4 marks -k 

> Out of the following four scheduling algorithms, which one can lead to starvation: FCFS , shortest job first , round robin , highest priority first ? Explain your answer.” [2 mark -c

> Consider a computer that has 1 GB of memory . 200 Mb is reserved for the operating system , and each process takes on average 200Mb . By how much would you expect the CPU utilization to increase by adding an additional gigabyte of memory ? Assume that the I/O rate is 80% and that each additional process takes up 200Mb.” [2 marks - a] 

# Question 5

> Explain virtual memory with paging . Include an explanation of address translation work in a paged system with virtual memory and a single level page table . Illustrate your answers where possible.” [9 marks - c] 

> Is the page table of a process updated in user or in kernel mode? Explain your answer. ” [2 marks -c] 


> Consider the following decimal addresses: 24575, 29645, and 44719. What are their virtual page numbers and offsets for a 4KB page size?” [3 marks - a] 

> Translation look aside buffers are used to speed up address translation. Assuming the following numbers/access times A 12ns associative TLB lookup A 150ns memory access time A single level page table Calculate the access time for a TLB hit, a TLB miss, and the estimated access time and slowdown for a 95% hit rate. ” [3 marks - a] 
