# Question 1
1. Process management
  - Greater processing power and more memory = ability to multiprocess
  - OS needs to provide APIs for creating and managing user processes
  - OS also needs to schedule processes so maximise CPU usage and share resources evenly

2. Memory management
  - Much more memory available now, and shared between multiple processes
  - Need to secure memory access so memory addresses can only be accessed by owning process(es) 
  - Processes now consume much more memory - need to perform swapping to keep only what is needed
in memory = implement paging

3. File system design (!)
  - Hard disks have much greater capacities now
  - Need to be able to track available space in the disk
  - Most file systems keep a list of blocks of fixed size, in a bitmap or linked list

4. Disks
  - Hard disks are significantly slower than volatile memory or CPU because of moving head
  - OS has to try to maximise the usage of the disk using scheduling
  - Order queued operations to try to maximise use in one movement of the read/write head

# Question 2
- Threads share more things between each other - data, code and files
- This means context switching from one thread to another (of same process) has less overhead
- The address space remains the same between them


1. User-level threads
  - Where maximum performance is required - avoids system calls which trigger context switching
  - Where portability is required - not all operating systems provide kernel thread implementation

2. Kernel-level threads
  - In most other cases - API is simpler to use for programmers


- RR loops around the queue, executing each process in turn (maybe with time slice)
- I/O bound processes will use little of their allocated time, yet have to wait for all CPU bound 
processes to take their turn


1. Scheduling timeline (time slice = 50)
  - SJF:
    - C: 0 - 11
    - D: 12 - 26
    - A: 27 - 57
    - B: 58 - 114

  - Priority:
    - A: 0 - 31
    - B: 32 - 89
    - C: 90 - 100
    - D: 101 - 116

  - RR:
    - A
    - B
    - C
    - D
    - A
    - B
    - A
    - B

2. Average response time

# Question 3

Hard links refer to the i-node of the file that they point to.  
Since these differ between filesystems, if a hard link is copied to another filesystem, it is
highly unlikely that the copy will refer to the desired file


10,000 rpm = 1000/6 rps
1 ms = 0.001 s
so 1 ms causes 1/6 of a revolution
1/6 *600 = 10 sectors passed in 1 ms
So cylinder skew should be 10 sectors


1. FCFS
  - 61 = +5
  - 149 = +88
  - 230 = +81
  - 48 = +182
  - 216 = +168
  - 54 = +162
  - 192 = +138
  - 262 = +70
  - 220 = +42
  - 255 = +35
  - Total: 971

2. Shortest seek time
  - 61 = +5
  - 54 = +7
  - 48 = +6
  - 149 = +101
  - 192 = +43
  - 216 = +24
  - 220 = +4
  - 230 = +10
  - 255 = +25
  - 262 = +7
  - Total: 231

3. Circular scan w/ look

# Question 4


Thrashing in when an OS repeatedly swaps memory pages in and out of main memory and the swap
storage as they are requested.  
This can occur in scenarios of high memory usage where all pages are in use.


When compiling, programs don't know where in the address space of a computer they will be loaded
when they are run.  
To work around this, they simply assume they will start at 0x0 - all static addresses used in the
program will be relative to 0x0.  
The program relies upon the OS to translate these static addresses to the real address in memory
by adding an offset - the first memory address into which the program was loaded.


SJF and highest priority can lead to starvation since they re-order the ready queue as new 
processes arrive.  
In SJF, longer jobs are starved if jobs shorter than them keep being queued.  
In highest priority with static priorities, lower priority jobs are starved if higher priority ones
keep being queued.


# Question 5


Programs refer to virtual memory whenever they reference memory addresses.  
These addresses do not refer directly to physical memory addresses; the limit for virtual addresses
is caused only by the max value that can be stored in a register (2^64 on a 64-bit system).  
In order to be able to handle requests for addresses outside of the range of the physical memory
available, an OS needs to convert virtual into physical memory addresses. 
This is done using a page table.  
The page table breaks down memory into contiguous blocks of fixed sizes. Ranges of memory addresses
each refer to a different page. 
The first x bits of the address can determine the page number, and the last y bits determine the offset 
within that page. x - and thus y - vary depending on page size.
Page number is then converted to frame number (in physical memory) through the page table.
Since there is usually a much larger virtual memory space than physical, some memory data is stored
on a hard disk in 'swap space'. When an address in a page not in physical memory is requested 
(page fault) it 'swapped' into physical memory by replacing the last frame that has been accessed 
in physical memory. That is, the one that has least been used.


In kernel mode. If a process were able to update its own page table (in user mode) they would be
able to access any other process' memory, which would be a huge security issue.


1. 24575
  - /4096 = 5 rem 4095
  - Page: 5, offset: 4095

2. 29645
  - /4096 = 7 rem 973
  - Page: 7, offset: 973

3. 44719
  - /4096 = 10 rem 3759
  - Page: 7, offset: 3759


1. Hit
  - 12ns TLB lookup
  - 150ns memory access to read value
  - Total: 162ns

2. Miss
  - 12ns TLB lookup
  - 150ns to check page table for desired address
  - 150ns to get value at address 
  - Total: 312ns
